# One-Shot Federated Conformal Prediction

## 1.预知

### 1.1 分位数估计器

分位数估计器是一种用于估计总体分位数的统计方法。分位数是指将一组数据按照大小排序后，将其分为若干等份，每一份中的数值就是相应分位数的估计值。

常见的分位数包括中位数（50%分位数）、四分位数（25%和75%分位数）等。分位数估计器的目标是根据样本数据来估计总体的分位数。

### 1.2一次性联邦学习环境

一次性联邦学习环境是指在联邦学习中，参与方只进行一轮的模型训练和参数更新，然后就结束了合作。在这种环境下，参与方之间只共享一次数据和模型，而不是像传统的联邦学习那样进行多轮的迭代训练。

### 1.3 泊松二项式

泊松二项式（Poisson binomial）是一种特殊的概率分布，用于描述多个独立且具有不同成功概率的二项分布的和。在泊松二项式分布中，考虑了多个独立的二项分布，每个二项分布有不同的成功概率

### 1.4 置信区间

置信区间（confidence interval）是统计学中用于估计总体参数范围的一种方法。它表示在给定的置信度水平下，总体参数的真实值有很大概率落在这个区间内

### 1.5 置信度水平

置信度水平（confidence level）是统计学中用于描述置信区间的概念。它**表示对于一个给定的置信区间，有多大的概率包含了真实的参数值**。

常见的置信度水平通常以百分比的形式表示，例如95%、99%等。这表示对于一个置信区间，有95%、99%等的概率包含了真实的参数值。换句话说，如果我们进行多次抽样实验并计算置信区间，那么在95%、99%的情况下，这些置信区间中大约有95%、99%的区间会包含真实的参数值。

置信度水平是在进行统计推断时非常重要的概念，它帮助我们评估置信区间的可靠性和确定性。通常，较高的置信度水平意味着更高的置信区间的宽度，因为我们更加确定真实参数值的范围。但是，较高的置信度水平也意味着更多的抽样实验或更大的样本量可能是必要的。

### 1.6 CQR

Conformalized Quantile Regression (CQR)是一种将分位数回归（quantile regression）与符合性预测（conformal prediction）相结合的统计方法。分位数回归是一种估计给定一组预测变量的条件分位数的技术。当预测变量与响应变量之间的关系不是线性的或者关注的是响应分布的特定分位数时，分位数回归非常有用。

符合性预测是一个提供机器学习模型预测的有效置信度或显著性度量的框架。它基于构建包含真实响应值的预测区间的思想，这个区间具有一定的概率。

CQR通过将符合性预测纳入分位数回归中，为估计的分位数提供有效的预测区间。它考虑了估计的分位数的不确定性，并为每个预测提供置信度的度量。这样可以在数据有限或受到噪声影响的情况下更可靠地估计条件分位数。

CQR的主要优势在于它提供了一种量化分位数回归预测的不确定性的原则性方法。它可以应用于各种应用领域，如金融、经济学和环境科学，其中准确估计条件分位数非常重要。

### 1.7 分位数回归

分位数回归（Quantile Regression）是一种用于估计给定一组预测变量的条件分位数的统计方法。与传统的普通最小二乘回归（OLS）不同，分位数回归能够提供关于不同分位数的回归系数估计，从而对数据的不同部分进行更准确的建模。

在分位数回归中，我们不再关注预测变量对于响应变量的平均效应，而是关注不同分位数下的条件效应。通过估计多个分位数，我们可以获得关于响应变量在不同条件下的整体分布的更全面的了解。

分位数回归的优势在于它对异常值和极端观测点具有鲁棒性。它能够更好地处理数据中存在的不对称、非线性或异方差的情况。此外，分位数回归还能够提供关于不同分位数的置信区间，从而提供关于估计的准确性的度量。

### 1.8 分位数回归林

Quantile Regression Forests (QRF) 是一种用于回归问题的机器学习算法。它结合了随机森林和分位数回归的思想，能够对目标变量的不同分位数进行建模和预测。

QRF的基本思想是通过构建多个决策树来拟合训练数据，并使用分位数损失函数来优化每个决策树的拟合能力。在预测时，QRF可以根据需要预测目标变量的不同分位数，从而提供更加全面和准确的预测结果。

与传统的回归算法相比，QRF具有以下优势：

1. 能够提供关于目标变量分布的更多信息，而不仅仅是均值。
2. 对于异常值和离群点具有更好的鲁棒性。
3. 可以通过调整分位数水平来控制预测的置信区间。

因此，Quantile Regression Forests在许多领域中都有广泛的应用，特别是在金融风险管理、医学研究和气候预测等领域。

### 1.9 校准集

校准集（Calibration Set）是在统计建模和机器学习中用于评估模型的性能和进行模型校准的数据集。在建立模型时，我们通常会将数据集分为训练集、校准集和测试集。

校准集的主要作用是评估模型的预测精度和确定模型的参数或超参数。通过在校准集上进行模型拟合和预测，我们可以评估模型的预测能力，并根据校准集的表现来调整模型的参数或超参数。

**对于校准集来说，每个客户端需要计算分数，并且将分数发给服务器来评估模型的性能。**

### 1.10 分数

**在保形预测中，分数用于衡量模型的预测准确性。它是一种评估指标，可以帮助我们了解模型在预测中的表现。**

分数的计算方法可以因具体问题而异，以下是一些常见的分数计算方法：

1. 准确率（Accuracy）：准确率是指模型预测正确的样本数占总样本数的比例。它可以通过以下公式计算：
   准确率 = (预测正确的样本数) / (总样本数)

2. 精确率（Precision）：精确率是指模型预测为正例的样本中，实际为正例的样本数占预测为正例的样本数的比例。它可以通过以下公式计算：
   精确率 = (真正例数) / (真正例数 + 假正例数)

3. 召回率（Recall）：召回率是指模型正确预测为正例的样本数占实际为正例的样本数的比例。它可以通过以下公式计算：
   召回率 = (真正例数) / (真正例数 + 假负例数)

4. F1分数（F1-Score）：F1分数综合考虑了精确率和召回率，是精确率和召回率的调和平均值。它可以通过以下公式计算：
   F1分数 = 2 * (精确率 * 召回率) / (精确率 + 召回率)

这些分数可以根据具体问题的需求选择使用。通常，我们会根据问题的特点和重要性来选择适合的评估指标。

需要注意的是，不同的问题可能有不同的评估指标和分数计算方法。在使用分数进行模型评估时，应该根据具体问题的需求选择适合的指标和计算方法。

### 1.11 保形预测

是一种用于机器学习和统计推断的框架，它提供了一种量化和控制预测置信度的方法。它的主要目的是为每个个体的预测提供一个预测区域或集合，而不仅仅是一个点预测。

**eg:为所需预测的样本计算出一个预测区间，如果一个用户的预测区间表明其有高概率肥胖，则将其预测为肥胖，区别与传统的预测，不仅仅是一个点预测。**

**优点**：更加可靠和校准的预测结果

#### 1.11.1 边缘覆盖

在保形预测中，边缘覆盖是指预测区间（或置信区间）对于目标变量的概率分布的覆盖程度。具体来说，边缘覆盖是指预测区间中包含目标变量真实值的概率。

#### 1.11.2 保形预测与分位数

在保形预测中，计算分位数是一种常用的方法来构建预测集。这是因为分位数能够提供对数据分布的详细描述，包括中心趋势和离散程度。通过计算分位数，我们可以获得数据的上界和下界，从而构建出一个范围，用于表示未来的可能性。

具体来说，计算分位数可以帮助我们：

1. 评估预测的不确定性：通过计算分位数，我们可以得到一系列的预测结果，例如中位数、上分位数和下分位数。这些分位数提供了一种度量未来可能性的方式，帮助我们评估预测的不确定性。
2. 提供预测的置信区间：通过计算上分位数和下分位数，我们可以构建出一个置信区间，用于表示未来观测值的范围。这可以帮助我们更好地理解预测结果，并提供一定的决策依据。
3. 考虑极端情况：通过计算极端分位数，例如上分位数和下分位数，我们可以考虑到可能发生的极端情况。这有助于我们对风险进行评估和管理，以及制定相应的应对策略。

### 1.12 评分函数

评分函数（score functions）是用于评估模型预测结果的一种方法。它们可以用于衡量模型的性能、准确性和泛化能力。以下是一些常见的评分函数：

1. 均方根误差（Root Mean Square Error，RMSE）：计算预测值与真实值之间的平均平方差，并取平方根。它是衡量预测结果与真实值之间的平均偏差的一种常用指标。
2. 平均绝对误差（Mean Absolute Error，MAE）：计算预测值与真实值之间的平均绝对差。它是衡量预测结果与真实值之间的平均偏差的另一种指标。

## 2.研究方向以及问题

应用保形预测，并且客户端与服务器只通信一轮的情况下，为了保证隐私性，同时使用了一个使用差分隐私版本的估计器。

### 2.1 对计算分数进行排序

在这个服务器与客户只通信一轮情况下，对计算分数进行排序不可能。在单论通信下，客户端应该向服务器发送什么以及，服务器进行怎样的聚合才能达到所需覆盖。

### 2.2 流程

客户端训练模型，在校准集上进行预测并且计算分位数，传到服务器，服务器根据分位数估计器进行分位数选择，调整参数，最后为测试集生成预测集。

## 3.解决问题

### 3.1定义分位数估计器

我们定义了一个分位数的估计器：每个代理向服务器发送一个本地经验分位数，服务器通过计算这些分位数的一个分位数来聚合它们。（根据客户端数量以及数据集大小）

#### 3.1.1预先假设

（1） 客户端具有n个相同的校准集

（2）提前给出模型训练算法，如FedAvg，这样就关注校准集的预测集而不是模型的训练步骤。

#### 3.2.2 分位数

客户端生成n个分数后，考虑将分位数发给服务器。**需要考虑的是怎样计算分位数以及服务器怎样聚合分位数**

#### 3.3.3 使用QQ

QQ算法会计算其所有本地分数中的第ℓ小的值，然后从这些值中选择第k小的值。

#### 3.3.4 用M来代替下届

根据定理3.2，可以得出我们需要找到第k个最小的l值，使用QQ算法，同时用M来代替1-α成为概率P的下届。

#### 3.3.5 使用FedCP-QQ

在[7.7](#7.7 Fedcp-QQ是什么)中，我们已经得知FedCP-QQ是怎样使用的了，最终服务器可以得到第k个最小的l。

### 3.2 加入差分隐私的Fed-QQ

#### 3.2.1 差分隐私

引入指数机制，将离散化分数用合适的效用函数变为区间。

#### 3.2.2  基于Fed-QQ

##### 3.2.2.1  第一处修改

局部的分位数计算被差分隐私分位数计算所取代。

##### 3.2.2.2 第二处修改

调整客户端和服务器的分位数顺序，以确保有效覆盖。

#### 3.2.3 具体应用

在服务器向客户端要第l个最小得分时，客户端应用差分隐私分位数算法，使用随机化算法向服务器发送bin。

### 3.3 加入差分隐私后，服务器如何计算



## 4.实验过程

### 4.1 合成数据 （5.1）

从[1,5]上的均匀分布中得出2000个独立的单变量随机变量X（只有一个特征）

#### 4.1.1 切分

划分为训练集和校准集，校准集划分为客户端为50个，每个客户端数据为20，同时生成大小为5000的数据集

#### 4.1.2  训练数据构建预测集

使用分位数回归林训练数据，

#### 4.1.3 对比结果

在对比图3中，FedCP-QQ返回的集合与数据中心化返回的集合相同，但是FedCP-Avg则具有较大差异，数据中可能有异常值，说明FedCP-QQ更具有鲁棒性。

### 4.2 真实数据（5.2）

#### 4.2.1 使用模型

岭回归的split-CP----通过交叉验证来调参

分位数回归森林的CQR

神经网络的CQR

#### 4.2.2 划分数据集

0.4训练集

0.4校准集：模拟联邦学习环境，将数据集划分为m个客户端，每个客户端有n个数据

0.2测试集

#### 4.2.3 结果

FedCP-QQ返回的覆盖率比期望的覆盖率还要好。

## 5.论文结论与未来展望

多项实验强调，我们的方法返回的预测集的覆盖率和长度与集中设置中返回的预测集中的预测集接近，这支持了FedCP-QQ是一种非常适合（一次性）FL场景的方法。然而，研究如何将我们的FL方法扩展到全共形或嵌套共形方法将是一件有趣的事情。一个有趣的研究方向是推导局部数据集不相同分布情况下的特定估计量。

## 6.部分参数

$$
α \ 错误覆盖率\\1-α即为准确率\\
m \ 客户端\\
f \ 预测器\\
$$



## 7.一些问题

### 7.1 l和k代表什么

对于每个代理，QQ算法会计算其所有本地分数中的第ℓ小的值，然后从这些值中选择第k小的值。

具体来说，假设有一组代理，每个代理都有多个本地分数。对于每个代理，QQ算法会将其所有本地分数按照从小到大的顺序排列，并选择其中的第ℓ小的值。然后，从这些第ℓ小的值中，QQ算法会再次按照从小到大的顺序排列，并选择其中的第k小的值作为最终的结果。

这个过程可以用来找到一组代理中的第k个最小的ℓ小值。

### 7.2 上界下界干什么用的

本文是将保形预测应用到联邦学习中，保形预测是一种用于生成置信区间的方法，为每一个预测样本生成一个置信区间，用置信得分来计算置信区间，用分位数来确定置信度区间的上下界。

### 7.3 s' 是什么分数

得分函数s，用于测量预测器误差的大小。

s'是用于Q函数举例的，Q(k)作用是输出所给分数集的第k个最小的值

### 7.4 用什么训练模型？

文中为了简化，假设训练模型算法是提前给出的，例如FedAvg。

### 7.5垃圾箱Bin干嘛的？

Private prediction sets 

在另一篇文献中具体解释

![image-20231018142043975](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142043975.png)

bins是用于将分数离散化的区间值。

### 7.6 M  ？？

用M表示概率P的下界，原本P>=1-α，由于需要找到第k个最小的l值，便用M来代替下界，同时p>=M>=1-α

### 7.7 Fedcp-QQ是什么

根据算法1

(1) 每个客户端输入本地的分数S，错误率α，以及根据公式计算发M

(2)对每个客户端来说，计算本地最小的l值并且将其发送给服务器

(3)服务器再根据传输的l值计算第k个最小的值

### 7.8 FedCP-QQ与一次性FL环境为什么适合？

一次性联邦学习环境要求客户端与服务器只通信一次，在应用保形预测的时候，需要将在客户端计算的分数发送给服务端，但是这个分数需要客户端将本地所有的分数传给服务器，然后服务器再将所有的分数进行排序，最后得到这个分数。因为隐私保护和通信消耗，这种方式在FL环境中是不适用的，通过应用FedCP-QQ可以只通信一次，适用于一次性FL环境。



### 7.9 分数是干啥的？

在保形预测中，需要计算校准集和通过校准集进行预测的点y，通过计算这两者之间的**误差分数**，进行调参，使最终的预测尽量准确。

### 7.10 分位数与分数

一个客户端训练结束后，计算分数，每一条数据可以计算出一个分数，所以得到S1,S2,S3........Sn,共有n个分数。

分数中的分位数是指将一组数据按照大小顺序排列后，将其分为若干等分的数值点。分位数可以帮助我们了解数据的分布和集中趋势。

例如数组1,2,3,4,5

分位数为50%，得到的数据为3

分位数为75%，得到的数据为4

### 7.11 知道分数后怎样作用在预测点X上？

每个客户端发送第l个最小分数，然后服务器再从这些分数中选出第k个最小分数，得到分数q,在spilt-CP方法中提供计算预测区间的方法。[8.6](#8.6 实验)

### 7.12对于找到l，k，定义一个下届M有什么作用吗

根据公式5，需要找到一个l，k使得概率p>=1-α，所以定义一个M使得p>=M>=1-α,

### 7.13 怎样找到l，k

l，k根据公式arg min｛M｝，好像是找到l和k使得M最小，l和k是在n和m这个范围中，所以需要遍历（1，n)和（1，m)使得M最小。

### 7.14 l\*和k\*是什么意思

因为要使得M最小，根据公式找到的l和k便是需要的l\*和k\*。

### 7.15 加入差分隐私后随机化后，服务器如何计算分数？

选取一个自由参数y，因为客户端返回的区间可能小于第l个参数，定义一个补偿lcor，让客户端返回l+lcor个最小的分数。



### 7.16 隐私参数

在差分隐私中，隐私参数越小，隐私保护越好，但是加入的噪声就越大。

### 7.17 $\hat{q}$是什么

在3.1，在集中式框架下，$\hat{q}$是一个分数是从$\lceil{(nm+1)(1-α)}\rceil$个最小分数，并且根据这个分位数寻找最小的分数(从m个客户端发送的分数中进行选择)

![image-20231019170731368](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231019170731368.png)



### 7.18 预测集在哪构建

首先数据分为训练集和校准集，在训练集训练后，生成校准集的预测数据，然后与原来的校准集生成分数。

### 7.19 有效覆盖集在哪

使用spilt-cp会返回一个有效集$\hat{C}(X)$,并且该有效集要满足

![image-20231018142136070](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142136070.png)



### 7.20 客户端传分数，服务端怎样利用

服务器再计算第k个最小分数，然后根据spilt-CP计算预测区间。

### 7.21 $\gamma$怎样与M关联计算

[8.5.3](#8.5.3 自由参数$\gamma$的选择(==有点看懂==))

### 7.22  预测区间与覆盖集C有上面关系吗

预测区间是每个方法经过训练后，可以得到的一个预测区间。

计算预测区间都需要先计算分数Q。[8.6.1](#8.6.1 合成数据)

而覆盖集C则需要根据以下计算，这两者之间都需要计算分数Q。覆盖集C由校准集预测出来的y组成，并且要满足以下条件。

![image-20231019160626032](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231019160626032.png)

新的预测点Y要满足以下条件。

![image-20231018142149149](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142149149.png)

## 8.本文概述

### 8.1 问题以及场景

#### 8.1.1 问题

应用保形预测在联邦学习中，并且在一次性联邦学习中，使用怎样的算法使通信交换的信息最有效，交换什么信息。并且评估预测的准确性。

#### 8.1.2 场景

在一次性联邦学习环境中，即客户端与服务器只通信一次，应用保形预测怎样使预测集的覆盖率更高，以及提出了差分隐私的Fed-QQ。

#### 8.1.3 提出的目的

为了量化预测的不确定性，即评估该算法的预测的准确率。

### 8.2 引言

#### 8.2.1为什么要应用保性预测？

保性预测是给出预测点的区间但是只能在集中式框架中，本文在FL环境下，构造出这样一个预测集，评估预测的准确性，并且只能通信一次。

#### 8.2.2 算法目的

构建一个覆盖集使得测试点(X,Y)中的Y落地在这个覆盖集中，并且Y在这个覆盖集上的概率P有一个下届 ,P>=1-α，即测试点Y属于这个覆盖集的概率要大于等于1-α。

![image-20231018142149149](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142149149.png)



#### 8.3.3 步骤关键

客户端向服务器传输(选择一个评分函数)分数(表示预测值和真实值之间的差距)，但是因为每个客户端的一个数据点都有一个分数，假设客户端有n个数据点，那么就有n个分数，这需要消耗很多次通信轮次，本文便提出了分位数交换（描述数据分数），每个客户端在通信一次的情况下，向客户端发送数据的分位数，服务器再聚合这m个位数，用以评估预测效果。

### 8.3 背景以及相关工作

#### 8.3.1 分裂保性预测

为了使用分裂保性预测，需要定义一个评分函数，但是在本文中并不需要选择一个特定的评分函数，所以设定评分函数是抽象的。

1.首先需要将数据集划分，划分为训练集和校准集。

2.预测器在训练集上训练，然后在校准集(共有n个数据)上预测并且通过评分函数计算得分$S_n$={$S_1$,$S_2$,.....$S_n$}。

3.给出测试点X和错误率α，使用spilt-CP构建覆盖集。

$\hat{Q}_k$  该函数的意思是，在所给出的n个分数中，找到第k个小的值。分数需要从小到大排列。在以下公式中  k=$\lceil{(n+1)(1-α)}\rceil$。

该覆盖集满足：

![image-20231018142210598](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142210598.png)

==首先保形预测运用训练集训练后，在校准集上进行预测，每个校准点生成一个y，然后根据算法设置计算分数，以上公式覆盖集的意思是给出一个测试点X,然后算法生成y，用函数s计算(X,y)的分数，该分数需要小于等于Q,然后该覆盖集由实数y构成，并且条件是每个s(X,y)不得超过Q。==



且仍然需要满足：

新的测试点Y在这个覆盖集的概率要大于1-a。

![image-20231018142149149](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142149149.png)

#### 8.3.2 联邦学习相关工作

对于每个客户端计算一个分位数$\hat{Q}_{\lceil (n+1)(1-α)\rceil}$，将其发送发送到服务器后，平均这些分位数。

首先并没有证明预测集有效覆盖，并且这个方法不具有鲁棒性。



### 8.4 Fed-QQ算法

#### 8.4.1 设置和目标

假定每个客户端拥有相同的n个校准集(不同校准集在附录A.1),使用训练算法FedAvg。因此关注于预测集的校准。

首先预测集$\hat{C}(X)$={y∈R:s(X,y)<=$\hat{q}$}需要包含测试点Y,并且满足![image-20231018142149149](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142149149.png)，在集中式环境中，将$\hat{q}$选作$\lceil{(nm+1)(1-α)}\rceil$个最小的分数。

在集中式的框架中，spilt-CP需要客户端发送本地全部分数并且将其进行排序，这在一次性联邦学习中是不现实的，因为隐私安全和通信消耗。



**所以本文需要在一次性联邦学习中，客户端经过一次通信，并且服务器聚合客户端发来的数据找到这个所需的q，使得以下两个条件满足。**

![image-20231018142149149](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142149149.png)

![image-20231018142210598](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142210598.png)

#### 8.4.2 提出Fed-QQ

（1） 首先QQ方法改为将每个客户端发送本地分数集$S^j$的分位数。

（2）那么问题就变成了客户端发送分数集的哪一个分位数，以及客户端怎样聚合这些分位数

（3）定义QQ

![image-20231018142309472](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142309472.png)

找到每个客户端第l小的分数，再从m个分数中找到k小的分数。

(4) 为了找到l，k，需要修改P的下界(使得M只取决于m,n,l,k)

![image-20231018142327692](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142327692.png)



（5）FedCP-QQ

对于l∈(1,n)，k∈(1,m),首先使用(4)中的公式计算M，然后从中选出最小的M，并且可以得到\*,k\*。

对于每个客户端发送第l\*个最小分数，然后服务器再聚合得到第k\*个最小分数。

![image-20231018142343603](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142343603.png)

最终使得覆盖集$\hat{C}$满足以下条件。

![image-20231018142413281](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142413281.png)

![image-20231018142433443](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142433443.png)

##### 8.4.2.1 特殊情况

###### 8.4.3.1 客户端只有一个数据

每个客户端发送唯一的分数，同时服务器计算第k个最小分数。

k=$\lceil{(n+1)(1-α)}\rceil$，满足以下条件去得到分数的有效覆盖集。

![image-20231018142210598](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142210598.png)

###### 8.4.3.2 客户端有无限个数据

每个客户端首先发送第l个最小分数，l=$\lceil{(n+1)(1-α)}\rceil$，**每个代理实际上已经发送了S的分布的阶数（1-α）的真实分位数**。因此，服务器可以选择这些值中的任何一个，并获得一个有效的集合。

##### 8.4.2.2 计算优化

对M的计算优化，提出对M和$l^*$和$k^*$的计算可以预先计算和重复计算。

#### 8.4.3 覆盖率的上界

构建覆盖率的上界，保证预测集不会过大。

**1、**在集中式的环境中，spilt-CP能够给出P的上界，P>=$1-α+1/(mn+1)$。

若是只有一个客户端或者客户端之间不合作，则上界变为$1-α+1/(n+1)$。

![image-20231018142801852](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142801852.png)

使用此方法中的P($\hat{C}_{l^*，k^*})$来与其他两个方法来对比，同时P与集中式的上界接近。

#### 8.4.4 条件覆盖确保  （==没看懂==）



#### 8.4.5 数据异质性的影响 (==没看懂==)



### 8.5 差分隐私下的Fed-QQ

基于差分隐私下使用Fed-QQ

#### 8.5.1 差分隐私

有一个原本的数据集D，若是将其中一个数据换成另外一个数据，对于攻击者来说分辨不出该数据集来自D还是D‘，那么该数据隐私得到了保护。

![image-20231018143247873](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018143247873.png)

其中有一个隐私参数$\varepsilon$,若是该值越小，则隐私性越强。

其中 0=$e_0$<$e_1$<........<$e_{B-1}$<$e_B$=$S_{max}$，$I_b$=($e_{b-1}$,$e_b$]

![image-20231018142822107](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018142822107.png)

1. 对于数据集中的每个数据点 `Si`，通过找到 `Si` 属于的区间 `Ib` 来计算分数的离散化值 `S¯i`。换句话说，将每个数据点映射到其对应的区间。
2. 对于每个区间 `b = 1, ..., B`，按如下方式计算权重 `wb`：
   - 计算区间 `b` 中的数据点 `i` 的数量，使得 `S¯i < eb`==即在$e_b$这个区间中找出在其左边的分数i的数量，并且最大的$\overline{S}$不能超过$e_b$==。这代表区间左侧的数据点数量。
   - 计算区间 `b` 中的数据点 `i` 的数量，使得 `S¯i > eb`。这代表区间右侧的数据点数量。
   - 计算 `wb` 为这两个数量中的较大值，同时考虑分位数 `q` 和 `1-q`。这个权重反映了区间内的数据分布。
3. 计算 `∆q` 为 `1/q` 和 `1/(1-q)` 中的较大值。这用于为隐私缩放噪声。

**输出**：

- 根据步骤2中计算的权重，基于概率 `e^(-εwb / (2∆q))` 输出区间 `eb`。

**该算法通过在步骤2中计算的权重中添加噪声来确保差分隐私。噪声的程度由隐私参数 `ε` 和权重的敏感性（受 `q` 影响）决定。**通过添加噪声，该算法使得难以确定贡献到估计分位数的具体数据点，从而提供隐私保护的保证。

需要注意的是，具体的 `ε` 选择以及数据分区为区间可能会影响最终输出中准确性和隐私之间的权衡。

#### 8.5.2 将差分隐私应用至Fed-QQ中

![image-20231018160225407](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018160225407.png)

原本客户端计算第l个最小分数，即需要发送分数，现在被算法2取代，发送加入噪声的随机区间$e_b$。

（1）首先根据算法1计算出所需的l和k

（2）返回的区间$e_b$可能小于实际所需的l，加入一个补偿$l_{cor}$

![image-20231018162256705](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018162256705.png)

所以实际返回第($l$+$l_{cor}$)个最小分数。

（3）根据公式计算所取的分位数q

![image-20231018162433153](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018162433153.png)

(4) 对于m个客户端来说，发送经过算法2处理过的$\hat{Q}_l$。

（5）最后服务器再计算第k个最小分数。

#### 8.5.3 自由参数$\gamma$的选择(==有点看懂==)

为了接近没有隐私的FedCP-QQ，$\gamma$应该取0并且$\varepsilon$趋向无穷大(隐私参数越小，加入噪声越多)。寻找$\gamma$的原则是：在之前计算的表M中，寻找最小数量关联的$\gamma$，即最小覆盖率M。

#### 8.5.4 隐私的放大和聚合(==没看懂==)



### 8.6 实验

（1） 使用spilt CP

​         $\hat{f}$是一个标准的回归，分数函数s(X,Y)=|Y-$\hat{f}$(X)|，最终的结果预测集为一个区间，[$\hat{f}(X)\pm\hat{q}$]。

（2）使用CQR

分数函数 ：![image-20231019155852429](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231019155852429.png)

构建的预测区间![image-20231018202401900](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018202401900.png)

（3） 对于以上两种方法，使用Fed-QQ 来寻找$\hat{q}$的值。

#### 8.6.1 合成数据

（1）从[1,5]中抽样2000次生成$X_1$.........$X_{2000}$。

（2） 从泊松分布中提取Y

![image-20231018203302400](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018203302400.png)

(3)将数据划分为训练集和校准集(均分)，为了模拟联邦学习环境，设置客户端为50个，每个客户端拥有校准集20个，最后生成5000个测试集。

#### 8.6.2 训练数据

使用CQR训练数据并且构建预测集。

#### 8.6.3 合成数据实验结果

首先设置α=0.1。（X,Y)为测试点。

从图中可以看出FedCP-QQ几乎与集中式环境下得到的直线重合。而FedCP-Avg则高于其他两条线。

原因：异常的存在，以及FedCP-Avg 算法的平均策略对异常值的干扰较差，不具有鲁棒性。而FedCP-QQ则具有较好的鲁棒性以及产生了更小的有效集。

![image-20231018205312648](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018205312648.png)

#### 8.6.4 真实数据

数据来源：

![image-20231018210940560](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018210940560.png)

https://archive.ics.uci.edu/dataset/446/scadi



#### 8.6.5使用模型

岭回归的 spilt-CP

分位数回归森林的CQR

神经网络的CQR

#### 8.6.6 结果

设置α=0.1

（1）在集中式环境中使用CP

（2）在联邦学习环境中使用FedCP-QQ和FedCP-Avg

（3）将数据集划分为40%训练集，40%校准集和20%测试集

（4）模拟联邦学习环境，将校准集划分为mn，即m个客户端，每个客户端n个数据。

（5） 对于每种方法，计算测试点在预测区间的覆盖率。

![image-20231019154719898](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231019154719898.png)

根据上面公式构造覆盖集$\hat{C}$，

结果如下图：

​				                     m>>n 									    	m<<n

![image-20231018212032164](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231018212032164.png)

**确定覆盖率**：对于每个测试样本，检查它的真实观测值是否落入相应的置信区间内。如果真实观测值在置信区间内，将其视为覆盖。然后，计算测试集上的经验覆盖率，即所有覆盖的观测值数量除以测试集中总观测值的数量

**图分析**：可以看出，图中间的白点表示覆盖率(测试点Y落在覆盖集上)，P高于期望的覆盖率0.9，与集中式框架下的覆盖率较为接近；并且使用FedCP-QQ生成的覆盖集长度接近集中式框架下的覆盖集长度。

### 8.7 额外的实验

####  8.7.1  当客户端有不同的数据集n

在主文中，为了方便计算，将每个客户端都设置成拥有相同的数据点n。

计算M的方法变为：

![image-20231020133804684](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231020133804684.png)

方便计算，将l计算固定：

![image-20231020134028608](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231020134028608.png)

结果：

![image-20231020134040974](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231020134040974.png)

#### 8.7.2 在每个数据集上单独实验FedCP-QQ

**B.1**

![image-20231020134542657](C:\Users\23671\Desktop\研一\文献阅读\assets\image-20231020134542657.png)
